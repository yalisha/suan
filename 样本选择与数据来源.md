### 一、样本选择与数据来源

#### (一)数据来源与采集

1. 核心数据集

本研究使用新浪微博热搜榜的历史数据作为核心数据源。微博作为中国最大的社交媒体平台之一,其热搜榜单是观察算法治理效应的理想场景:该榜单通过算法实时聚合用户浏览、搜索、讨论等行为数据,动态生成并展示当前最受关注的50个话题。热搜榜不仅是用户获取信息的重要入口,更是舆论热点的风向标,其内容分发逻辑直接受到平台算法治理策略的影响。

数据采集的时间窗口为2024年2月1日至2025年10月1日,跨度共计608天。该时间段完整覆盖了2024年10月12日算法治理政策实施的前后阶段,其中政策前观测期为253天(2024年2月1日至10月11日),政策后观测期为355天(2024年10月12日至2025年10月1日)。选择此时间窗口的原因有三:其一,政策前后各保留足够长的观测期(Pre期约8个月,Post期近12个月),可有效识别政策的短期冲击与中长期效应;其二,该窗口覆盖了春节、暑期等关键时段,能够控制季节性因素对热搜内容的影响;其三,避免了其他重大突发事件(如疫情政策调整、重大国际事件)对热搜生态的系统性干扰。

原始数据包含以下关键维度:(1)话题名称,用于识别具体议题;(2)热度值(微博官方计算的综合指标,整合了阅读量、讨论量、搜索量等多维度数据),用于衡量话题的注意力强度;(3)上榜时长,记录话题在榜单上的持续时间,用于测度注意力密度;(4)话题主持人分类(`host_category_raw`),微博平台为每个话题预设的内容类别标签,共包含82个细分类别(含"其他");(5)时间戳,精确到分钟级别,用于构建时间序列与事件研究设计。

2. 数据获取方式

数据通过第三方数据平台获取。该平台采用API接口与网页爬虫相结合的方式,按小时频率采集热搜榜单快照。相较于手工抓取,第三方平台具有数据完整性高、时间戳准确、字段标准化等优势,能够有效避免因网络波动或平台反爬机制导致的数据缺失。为验证数据质量,我们对比了不同日期的榜单快照与微博官方页面的实时数据,确认关键字段(话题名称、排名、热度值)的一致性均在98%以上。

3. 辅助数据集

为测量H2中提出的内容质量指标(官方媒体占比),我们对话题的信源属性进行了人工标注。具体而言,抽取全样本中上榜频次排名前5000的高频话题(覆盖总热度值的约85%),由研究者依据话题主持人的账号属性进行分类:(1)官方媒体,包括党媒(如人民日报、新华社)、政务账号(如公安、卫健委)及传统主流媒体(如央视新闻、澎湃新闻);(2)自媒体及其他,包括个人账号、商业机构、娱乐工作室等。该辅助数据集将用于H2a关于社会类内容质量提升的检验。

---

#### (二)样本筛选与处理

1. 筛选标准

为确保数据质量与分析的有效性,我们对原始数据实施了以下筛选程序:

第一,剔除时间戳缺失或异常的记录。极少数观测值因系统故障或传输错误导致时间信息不完整,此类记录无法准确归入政策前后时段,故予以删除。

第二,删除空话题或无效话题。部分榜单位置因平台技术原因显示为空白或系统占位符(如"加载中"),此类记录不代表实际内容,予以剔除。

第三,排除平台未明确分类的话题。微博原始数据中,部分话题的`host_category_raw`字段被标注为"其他",该类别涵盖了平台无法归类或边界模糊的话题。由于"其他"类别缺乏明确的内容属性,无法纳入后续的类别对比分析,故将其删除。这一处理符合学术惯例:在研究明确定义的类别差异时,排除含义模糊的观测值可提升内部效度,代价是部分损失样本覆盖率(详见稳健性检验中的敏感性分析)。

2. 最终样本特征

经过上述筛选,最终样本包含253,227条观测值,对应约215,083个独立话题(部分话题在不同时段多次上榜),覆盖608个日样本。样本的时间分布呈现以下特征:

(1)日均频次:平均每日约416条话题上榜记录(去重前),剔除"其他"类别后的日均观测值略有下降但仍保持在较高水平。

(2)极值与波动:单日最少上榜话题数为34条(2025年8月1日),最多为582条(2024年11月15日)。后者恰好位于政策实施后约一个月,反映出政策冲击可能引发的短期波动(详见实证结果部分的动态效应分析)。多数日期的上榜话题数集中在370–460条之间,表明样本整体稳定。

(3)政策前后对比:Pre期和Post期的日均话题数无显著差异,初步排除了样本量变化对结果的系统性干扰。

3. 样本代表性论证

本研究的样本在时间维度和内容维度上均具有较强的代表性:

时间代表性:608天的观测窗口覆盖了完整的季节周期(春节、清明、五一、暑期、国庆等),能够有效控制节假日效应与季节性波动，避免将短期随机波动误判为政策影响。

平台代表性:微博作为中国用户规模最大的社交媒体平台之一(月活跃用户超5亿),其热搜榜是公众获取即时信息的主要渠道。根据新浪微博2023年财报,用户日均使用时长约52分钟,其中热搜浏览时长占比15–20分钟,表明热搜榜在用户注意力分配中具有核心地位。因此,基于微博热搜榜的研究结论对于理解算法治理在社交媒体生态中的作用机制具有重要参考价值。

样本流失影响:剔除"其他"类别后的样本损失率相对有限。敏感性检验(见稳健性部分)表明,保留"其他"类别进行分析时,核心结论不变,说明样本筛选未引入显著的选择性偏误。

---

#### (三)话题分类方法

1. 分类依据与策略

本研究直接沿用微博平台预设的`主持人分类`字段作为话题分类的基础。该字段由微博官方维护,基于话题主持人的账号属性、发布内容的历史特征及平台编辑规则自动生成,共包含81个细分类别(剔除"其他"后)。选择平台原始分类的理由有三:

其一,减少测量误差。平台分类基于大规模用户行为数据与算法模型训练,相较于研究者的二次编码,具有更高的稳定性与一致性。人工分类可能因标注者主观判断差异导致分类边界模糊,而平台分类规则在整个观测期内保持不变,避免了时间维度上的系统性偏误。

其二,贴近平台决策逻辑。算法治理政策的实施主体是平台本身,平台的内容分发策略必然依赖其内部分类体系。使用平台原始分类可最大程度还原算法调整的真实作用路径——平台如何识别、区分并差异化对待不同类别的内容。

其三,提升研究可复制性。平台分类数据可直接获取且公开透明,后续研究者可基于相同分类标准进行验证或扩展分析,增强研究的外部效度。

2. 核心类别的界定与聚合

虽然原始数据包含81个细分类别,但为聚焦理论假设中的核心对比——"高风险社会类内容"与"低风险娱乐类内容"之间的差异化效应——我们选取了占比排名前十的类别作为主分析对象。这十大类别合计覆盖约86%的样本量,具体分布如表1所示:

[表1] 话题类别分布(Top 10,已剔除"其他")

| 类别 | 占比 | 累计占比 | 分类归属 |
|------|------|----------|----------|
| 社会 | 34.82% | 34.82% | 社会类 |
| 明星 | 11.86% | 46.68% | 娱乐类 |
| 体育 | 10.43% | 57.11% | 其他类 |
| 时事 | 6.52% | 63.63% | 其他类 |
| 游戏 | 4.82% | 68.45% | 其他类 |
| 明星-内地 | 4.61% | 73.06% | 娱乐类 |
| 综艺 | 4.30% | 77.36% | 其他类 |
| 电视剧 | 3.17% | 80.53% | 其他类 |
| 搞笑 | 2.69% | 83.22% | 其他类 |
| 财经 | 2.46% | 85.68% | 其他类 |

基于理论假设中关于"监管强度的非对称性"(高风险内容面临更严格的质量约束与审核成本),我们将上述类别进一步聚合为两个核心对比组:

社会类:包括"社会"标签下的话题(占比34.82%)。该类别主要涵盖公共事件、民生议题、社会现象等具有较强舆论属性的内容。根据《算法专项治理清单指引》第11条(防范违规操纵榜单)与第23条(识别违法网络谣言),此类内容被纳入平台重点监测范围,面临更高的信息真实性、来源可溯性要求,构成典型的"高风险、高合规成本"类别。

娱乐类:包括"明星"与"明星-内地"两个标签(合计占比16.47%)。该类别主要涵盖明星动态、娱乐八卦、粉丝互动等内容,其特征是用户参与度高但舆论风险相对可控。此类内容的外部性主要局限于版权侵犯、隐私泄露等局部问题,监管多采取"守住底线"的防御性姿态,相较于社会类内容享有更宽松的合规环境,构成典型的"低风险、低合规成本"类别。

其他类别(体育、时事、游戏、综艺、电视剧、搞笑、财经,合计占比48.71%)暂不纳入本文的核心对比分析,但将在稳健性检验中探讨其作为"中间类别"的作用(详见第四部分)。

3. 分类方案的合理性论证

上述聚合方案基于以下考虑:

聚焦典型对比:选择"社会"与"明星"类别作为核心对比组,是因为二者在监管强度、内容属性、用户群体等维度上呈现出最鲜明的两极分化特征。这种"极端对比"(extreme comparison)策略有助于清晰识别算法治理的差异化效应,避免因类别边界模糊导致的统计检验力不足。

避免分类歧义:部分类别(如"时事")虽然也可能涉及公共话题,但其内容边界相对模糊——既可能包含重大政策解读(高风险),也可能包含轻松时事评论(低风险)。为避免分类异质性削弱结果的内部效度,我们采取保守策略,仅将平台明确标注为"社会"的话题纳入高风险组。同理,"综艺"、"电视剧"虽属娱乐范畴,但可能涉及价值导向争议(如"耽改剧"审查),其风险属性介于社会类与纯娱乐类之间,故暂不纳入核心分析。

理论一致性:本研究的理论假设聚焦于"监管对不同风险类别的非对称冲击"。通过选择风险属性最为分明的两个类别,可最大化地还原理论模型中 $\xi_S \gg \xi_E$ 的设定(即社会类监管强度显著高于娱乐类),增强理论推导与实证检验的匹配度。

稳健性考量:需要说明的是,本研究采取的聚焦策略虽然提升了类别对比的清晰度,但也牺牲了部分样本覆盖率。作为稳健性检验,我们在第四部分采用扩展分类方案(将"时事"、"财经"纳入广义社会类;将"综艺"、"电视剧"、"搞笑"纳入广义娱乐类),结果表明核心结论保持稳健(详见表X)。这证实了本文的发现并非由特定类别选择驱动,而是反映了算法治理在风险分层逻辑下的系统性效应。此外,我们还进行了基于连续风险评分的异质性分析,发现政策效应沿风险梯度呈现单调变化,进一步验证了理论机制的普适性(详见表Y)。

### (一)变量定义与测量

#### 1. 核心因变量

**H1相关变量：注意力分布集中度**

(1) **Shannon熵** ($H_t$)

Shannon熵用于测度每日热搜榜单注意力分布的均匀程度(Oestreicher-Singer & Sundararajan, 2012)。对于第$t$天的榜单，设共有$N_t$个话题上榜，第$i$个话题的热度值为$V_{it}$，则其注意力份额为：

$$
p_{it} = \frac{V_{it}}{\sum_{j=1}^{N_t} V_{jt}}
$$

Shannon熵定义为：

$$
H_t = -\sum_{i=1}^{N_t} p_{it} \ln p_{it}
$$

该指标取值范围为$[0, \ln N_t]$。$H_t$越大，表示注意力分布越均匀，去中心化程度越高。为便于跨日比较(不同日期上榜话题数可能不同)，我们采用**归一化Shannon熵**：

$$
H_t^{\text{norm}} = \frac{H_t}{\ln N_t}
$$

其中$H_t^{\text{norm}} \in [0,1]$，值越接近1表示分布越接近完全均匀(Zhao et al., 2024)。

(2) **Herfindahl-Hirschman指数** ($\text{HHI}_t$)

HHI广泛用于测度市场集中程度(Hosanagar et al., 2014)，在本研究中用于衡量注意力的集中程度，定义为：

$$
\text{HHI}_t = \sum_{i=1}^{N_t} p_{it}^2
$$

该指标取值范围为$[1/N_t, 1]$。$\text{HHI}_t$越大，表示注意力越集中于少数头部话题；反之则表示分布越均匀。根据美国司法部《横向合并指南》的惯例，$\text{HHI} > 0.25$通常被视为高度集中市场。

---

**H2相关变量：内容质量代理指标**

(3) **官方媒体占比** ($\text{Official}_{ct}$)

对于类别$c$在第$t$天上榜的话题集合，官方媒体占比定义为：

$$
\text{Official}_{ct} = \frac{\text{官方媒体主持话题数}}{\text{类别}c\text{当日上榜总话题数}}
$$

官方媒体包括：党媒(人民日报、新华社等)、政务账号(公安、卫健委等)、传统主流媒体(央视新闻、澎湃新闻等)。该指标数值越高，表示内容信源质量越高、合规性越强(He et al., 2024)。

(4) **内容规范性指数** ($\text{Compliance}_{ct}$)

参考He等(2024)关于平台内容治理的研究，我们构建内容规范性指数以测度话题标题的合规程度。具体而言，通过以下三个维度评估：

- **煽动性词汇密度**：识别标题中的情绪化词汇(如"震惊"、"崩溃"、"炸了"、"怒了")出现频率
- **标点符号异常**：统计连续感叹号(如"!!!")、问号堆叠(如"???")等非规范用法
- **数字夸张表达**：检测如"100%"、"史上最"、"第一"等绝对化表述

内容规范性指数定义为上述三个维度的标准化得分之和的负值(乘以-1使得数值越高表示越规范)。该指标借鉴了Dehling和Sunyaev(2024)关于信息透明度实践的测量框架，数值越高表示内容越规范、标题党特征越少。

---

**H3相关变量：注意力份额**

(5) **类别注意力份额** ($\text{Share}_{ct}$)

类别$c$在第$t$天获得的注意力份额定义为：

$$
\text{Share}_{ct} = \frac{\sum_{i \in c} V_{it}}{\sum_{j=1}^{N_t} V_{jt}}
$$

其中$\sum_{i \in c} V_{it}$为类别$c$所有上榜话题的热度值之和，$\sum_{j=1}^{N_t} V_{jt}$为当日所有话题的热度值总和。热度值(Heat Index)是微博平台综合用户阅读量、讨论量、搜索量等多维度行为数据计算得出的标准化指标，已被广泛用作社交媒体注意力强度的代理变量(Yi et al., 2022; Chen et al., 2024)。该指标反映了用户对特定内容的实际关注程度，相较于单一的曝光量或点击量，能更全面地捕捉注意力资源的分配状况(Gelper et al., 2021)。

(6) **类别上榜频次** ($\text{Count}_{ct}$)

类别$c$在第$t$天的上榜话题数量，用于测度内容供给规模。该指标与注意力份额相结合，可以区分"总量扩张"与"单位密度提升"两种不同的注意力增长模式。

---

**H4相关变量：注意力密度**

(7) **平均在榜时长** ($\text{Duration}_{ct}$)

类别$c$在第$t$天上榜话题的平均持续时间(小时)：

$$
\text{Duration}_{ct} = \frac{1}{N_{ct}} \sum_{i \in c} d_{it}
$$

其中$d_{it}$为话题$i$在榜单上的持续时长，$N_{ct}$为类别$c$当日上榜话题数。在榜时长是话题吸引力持续性的重要指标(Gelper et al., 2021)，时长越长表明话题能够持续吸引用户注意力，而非昙花一现。

(8) **注意力密度** ($\text{Density}_{ct}$)

类别$c$在第$t$天的单位话题平均热度：

$$
\text{Density}_{ct} = \frac{\sum_{i \in c} V_{it}}{N_{ct}}
$$

该指标反映了类内竞争强度的逆指标：密度越高，单个话题分摊到的注意力越充裕；密度越低，则意味着内容供给相对过剩，单个话题面临更激烈的类内竞争(Hosanagar et al., 2014)。注意力密度的变化揭示了平台算法在不同类别之间的资源配置策略：即使总注意力增加，若供给增长更快，单个内容仍可能面临"拥塞效应"(Benz et al., 2024)。

---

#### 2. 控制变量

为了排除混淆因素对因果推断的干扰，我们在所有回归模型中加入以下控制变量：

(9) **时间趋势** ($\text{Trend}_t$)

线性时间趋势变量，取值为1, 2, 3, ..., 608，对应研究期内的第1天至第608天。该变量用于控制研究期内可能存在的长期趋势，如平台用户规模的自然增长、内容生产者的累积进入等(Cao et al., 2024)。在ITS模型中，时间趋势的加入尤为重要，因为它能够区分政策冲击导致的"水平变化"(level change)与自然演化的"趋势变化"(slope change)。

(10) **周内固定效应** ($\text{DOW}_t$)

星期几的虚拟变量组，包括周一至周日七个指示变量。已有研究表明，社交媒体用户的在线行为在工作日与周末呈现显著差异：工作日期间社会类、财经类话题的关注度较高，而周末娱乐类、生活类话题的活跃度上升(Hosanagar et al., 2014)。因此，我们在模型中加入周内固定效应以控制这种系统性的周期性波动。具体而言：

$$
\text{DOW}_t = \{\text{Monday}_t, \text{Tuesday}_t, ..., \text{Sunday}_t\}
$$

其中每个虚拟变量在对应的星期取值为1，其他时间取值为0。在回归中，通常以周一(Monday)为基准组予以省略，以避免完全共线性。

(11) **月度固定效应** ($\text{Month}_t$)

月份虚拟变量组，包括1月至12月的十二个指示变量。该组变量用于控制季节性因素对热搜内容的影响。中国的舆论生态具有鲜明的季节性特征：春节期间(1-2月)娱乐类、文化类话题占比上升；暑期(7-8月)影视、综艺类内容活跃；国庆期间(10月)时事类、旅游类话题激增(Chen et al., 2024)。月度固定效应能够有效吸收这些可预测的季节性波动，避免将其误判为政策效应。

$$
\text{Month}_t = \{\text{Jan}_t, \text{Feb}_t, ..., \text{Dec}_t\}
$$

在回归中，通常以1月为基准组。

(12) **节假日虚拟变量** ($\text{Holiday}_t$)

$$
\text{Holiday}_t = 
\begin{cases}
1, & \text{若}t\text{为法定节假日或其前后一天} \\
0, & \text{其他}
\end{cases}
$$

中国的法定节假日包括：元旦(1月1日)、春节(农历除夕至正月初六)、清明节(4月4-6日)、劳动节(5月1-5日)、端午节(农历五月初五前后)、中秋节(农历八月十五前后)、国庆节(10月1-7日)。已有研究发现，节假日期间用户的媒体消费行为发生显著变化：总体在线时长增加，但内容偏好从严肃新闻转向娱乐休闲(Kleinberg et al., 2023)。此外，节假日前后一天也被纳入该变量，因为用户在假期预期下的行为模式已开始调整(如假期前一天的"出行攻略"热搜激增)。

(13) **平台总热度** ($\text{TotalHeat}_t$)

第$t$天所有上榜话题的热度值总和：

$$
\text{TotalHeat}_t = \sum_{j=1}^{N_t} V_{jt}
$$

该变量用于控制平台整体活跃度的日际波动。在某些特殊时期(如重大突发事件、全民关注的赛事)，平台总热度可能出现异常峰值，此时所有类别的绝对热度值都会上升，但相对份额未必变化(Rahman et al., 2024)。加入平台总热度作为控制变量，可以更准确地识别类别间的相对注意力再分配效应。

(14) **上榜话题总数** ($\text{TotalCount}_t$)

第$t$天上榜的独立话题数量$N_t$。虽然热搜榜理论上固定显示50个位置，但由于话题更新频率不同、部分位置可能短暂空缺，实际每日上榜话题数存在一定波动(如样本中最少34条，最多582条)。话题总数的变化可能影响注意力分布的集中度测度：当上榜话题数增加时，即使注意力总量不变，Shannon熵也会因分母增大而上升。因此，在H1的检验中加入该控制变量，或直接使用归一化Shannon熵，可以避免这种测量偏误。

---

#### 3. 分组变量与交互项

(15) **类别虚拟变量** ($\text{Social}_c$, $\text{Entertainment}_c$)

$$
\text{Social}_c = 
\begin{cases}
1, & \text{若类别}c\text{为社会类} \\
0, & \text{其他}
\end{cases}
$$

$$
\text{Entertainment}_c = 
\begin{cases}
1, & \text{若类别}c\text{为娱乐类(明星、明星-内地)} \\
0, & \text{其他}
\end{cases}
$$

这两个虚拟变量用于在DID框架中识别处理组。在H2、H3、H4的检验中，我们通过构建类别虚拟变量与政策虚拟变量的交互项($\text{Social}_c \times \text{Post}_t$, $\text{Entertainment}_c \times \text{Post}_t$)，来捕捉政策对不同风险类别的差异化冲击(He et al., 2024)。

(16) **政策虚拟变量** ($\text{Post}_t$)

$$
\text{Post}_t = 
\begin{cases}
1, & \text{若} \ t \geq \text{2024年10月12日} \\
0, & \text{若} \ t < \text{2024年10月12日}
\end{cases}
$$

该变量标识算法治理政策实施的时间节点。2024年10月12日，国家互联网信息办公室发布《算法分级分类安全治理清单(2024)》，要求各平台在30日内完成自查整改。我们将政策正式发布日作为断点，后续所有观测值被赋值为1。

---

### (二)计量模型设定

#### 1. 模型选择的总体策略

本研究采用**断点回归时间序列**(Interrupted Time Series, ITS)作为主要识别策略。相较于传统的双重差分(DID)设计，ITS在本研究情境下具有以下优势：

**第一，政策冲击的全局性特征**。2024年10月的算法治理政策对微博平台所有内容类别同时生效，不存在传统意义上"未受处理的纯对照组"。虽然政策对不同风险类别的约束强度存在差异，但所有类别都暴露在同一监管环境下。在此情境下，ITS通过对比政策前后同一主体(平台整体或特定类别)的时间序列变化，能够有效识别政策的净效应(Bernal et al., 2017)。

**第二，时间维度的高频观测优势**。本研究拥有608个日度观测值，构成了长时间序列数据。ITS设计充分利用了政策时点前后的密集观测，通过对比政策实施前后的"水平变化"(level change)与"趋势变化"(slope change)，能够更精细地刻画政策冲击的动态轨迹(Lopez Bernal et al., 2018)。这对于捕捉H3中提出的"娱乐类注意力超调-回落"等非线性动态效应尤为重要。

**第三，跨类别差异的嵌入式检验**。对于涉及类别对比的假设(H2-H4)，我们在ITS框架下引入**交互项设计**(interaction terms)，通过估计不同类别的政策效应系数($\beta_{\text{Social}}$, $\beta_{\text{Entertainment}}$)并进行组间差异检验，实现与DID类似的"差异化冲击"识别。这种"分组ITS + 系数差异检验"(stratified ITS with differential effects testing)的策略，在政策评估文献中被广泛认可(Kontopantelis et al., 2015)。

**第四，稳健性检验的多元化**。在主检验采用ITS的基础上，我们对关键假设(如H2)补充DID框架作为稳健性检验。具体而言，将娱乐类作为"相对对照组"(合规约束变化较小)，社会类作为"处理组"(合规约束显著提升)，验证质量分化效应是否稳健于不同的识别策略。

基于上述考量，下文分别阐述针对四个假设的具体模型设定。

---

#### 2. 模型1：注意力去中心化检验(H1)

H1关注平台整体层面的注意力分布变化，采用**经典ITS模型**：

$$
Y_t = \beta_0 + \beta_1 \text{Post}_t + \beta_2 \text{Trend}_t + \beta_3 (\text{Post}_t \times \text{Trend}_t) + \boldsymbol{\gamma}' \mathbf{X}_t + \varepsilon_t
$$

**变量说明**：
- 因变量：$Y_t \in \{H_t^{\text{norm}}, \text{HHI}_t\}$，分别为归一化Shannon熵和HHI指数
- $\beta_1$：政策实施后的即时水平变化(immediate level change)
- $\beta_2$：政策前的时间趋势斜率(pre-intervention slope)
- $\beta_3$：政策实施后趋势的增量变化(change in slope)，用于检验政策效应的持续性
- $\mathbf{X}_t$：控制变量向量，包括周内固定效应、月度固定效应、节假日虚拟变量、平台总热度

**预期结果**：
- H1a(熵值上升)：$\beta_1 > 0$ 或 $\beta_1 + \beta_3 \cdot \bar{t}_{\text{post}} > 0$
- H1b(集中度下降)：$\beta_1 < 0$ 或 $\beta_1 + \beta_3 \cdot \bar{t}_{\text{post}} < 0$

**标准误调整**：考虑到时间序列数据的自相关性，采用Newey-West标准误，滞后阶数根据Schwert准则选取。

---

#### 3. 模型2：内容质量分化检验(H2)

H2关注社会类内容质量的提升，主检验采用**单组ITS设计**，以社会类子样本为分析对象：

$$
\text{Official}_t^{\text{Social}} = \alpha_0 + \alpha_1 \text{Post}_t + \alpha_2 \text{Trend}_t + \alpha_3 (\text{Post}_t \times \text{Trend}_t) + \boldsymbol{\delta}' \mathbf{X}_t + u_t
$$

**变量说明**：
- 因变量：$\text{Official}_t^{\text{Social}}$为第$t$天社会类话题的官方媒体占比
- $\alpha_1$：政策后社会类质量的即时提升
- $\alpha_3$：质量提升的趋势变化（若显著为正，表明质量持续改善）

**预期结果**：H2a要求 $\alpha_1 > 0$ 且显著。

**稳健性检验(类别内DID设计)**：为排除官媒话题基于自身趋势上升的替代解释，我们在社会类内部构建DID模型，以官媒主持话题为处理组、非官媒主持话题为对照组：

$$
Y_{it}^{\text{Social}} = \theta_0 + \theta_1 (\text{Official}_i \times \text{Post}_t) + \theta_2 \text{Post}_t + \theta_3 \text{Trend}_t + \boldsymbol{\gamma}' \mathbf{X}_t + \eta_i + \varepsilon_{it}
$$

其中$Y_{it}^{\text{Social}}$为社会类中官媒（$i=1$）或非官媒（$i=0$）话题的上榜频次占比或热度占比，$\eta_i$为话题类型固定效应。$\theta_1 > 0$表明政策后平台在社会类中更倾向于推荐官媒主持的话题。

进一步地，我们对所有主要类别（娱乐、体育、时事等）重复上述DID估计。若仅社会类的$\theta_1$显著为正且通过平行趋势检验，而其他类别不显著，则支持H2的"质量分化"假说——监管仅在高风险类别触发了基于信源的质量筛选机制。

---

#### 4. 模型3：注意力再分配检验(H3)

H3涉及跨类别对比(社会类收缩 vs. 娱乐类扩张)，采用**分组ITS + 交互项设计**：

$$
\text{Share}_{ct} = \beta_0 + \beta_1^S (\text{Social}_c \times \text{Post}_t) + \beta_2^E (\text{Entertainment}_c \times \text{Post}_t) + \beta_3 \text{Trend}_t + \text{类别FE} + \text{时间FE} + \varepsilon_{ct}
$$

**变量说明**：
- 因变量：$\text{Share}_{ct}$为类别$c$在第$t$天的注意力份额(基于热度值)
- $\beta_1^S$：社会类的政策效应(预期为负)
- $\beta_2^E$：娱乐类的政策效应(预期为正)
- 类别FE和时间FE分别控制类别间的基线差异和时间维度的共同冲击

**预期结果**：
- H3a：$\beta_1^S < 0$ 且显著
- H3b：$\beta_2^E > 0$ 且显著
- 差异检验：$\beta_2^E - \beta_1^S > 0$ 且显著，验证"水床效应"

**动态效应扩展**：为检验H3b中的"超调-回落"模式，我们进一步估计动态ITS模型，将$\text{Post}_t$替换为一组月度虚拟变量($\text{Post}_t^{+1}, \text{Post}_t^{+2}, ..., \text{Post}_t^{+12}$)，观察娱乐类系数的时变轨迹。

---

#### 5. 模型4：注意力密度分化检验(H4)

H4检验社会类"少而精"vs. 娱乐类"多而稀"，模型设定与H3类似：

$$
Y_{ct} = \gamma_0 + \gamma_1^S (\text{Social}_c \times \text{Post}_t) + \gamma_2^E (\text{Entertainment}_c \times \text{Post}_t) + \gamma_3 \text{Trend}_t + \text{类别FE} + \text{时间FE} + u_{ct}
$$

**变量说明**：
- 因变量：$Y_{ct} \in \{\text{Duration}_{ct}, \text{Density}_{ct}\}$，分别为平均在榜时长和注意力密度

**预期结果**：
- H4a(社会类密度上升)：$\gamma_1^S > 0$ 当$Y_{ct} = \text{Duration}_{ct}$或$\text{Density}_{ct}$
- H4b(娱乐类密度下降)：$\gamma_2^E < 0$ 当$Y_{ct} = \text{Duration}_{ct}$或$\text{Density}_{ct}$
- 差异检验：$\gamma_1^S - \gamma_2^E > 0$

---

#### 6. 识别假设与检验

**ITS模型的核心识别假设**：在无政策干预的反事实情境下，结果变量将沿着既有趋势演化(no counterfactual trend break)。

**威胁与应对**：
- **同期事件干扰**：检查政策窗口期(2024年10月前后)是否存在其他重大冲击(如平台技术升级、竞争对手策略调整)，未发现显著干扰。
- **季节性混淆**：通过月度固定效应和节假日控制吸收可预测的季节波动。
- **自相关问题**：所有模型均采用稳健标准误(Newey-West或聚类调整)。

**稳健性检验预告**：
- 安慰剂检验：在政策前随机时点(如2024年7月1日)设置虚假断点，验证是否出现伪效应
- 敏感性分析：调整时间趋势设定(二次项、分段线性)、改变控制变量组合
- 替代性测度：使用Gini系数、Top 10占比等替代指标重新估计H1


### 表1：变量定义与测量

| 变量类型 | 变量名称 | 符号 | 定义与测量 | 数据来源 | 假设 |
|---------|---------|------|-----------|---------|------|
| **H1：注意力分布** |
| 因变量 | 归一化Shannon熵 | $H_t^{\text{norm}}$ | $H_t / \ln N_t$，其中$H_t = -\sum_{i=1}^{N_t} p_{it} \ln p_{it}$，$p_{it}$为话题$i$在第$t$天的热度份额；取值[0,1]，越大表示分布越均匀 | 微博热搜榜 | H1a |
| 因变量 | HHI指数 | $\text{HHI}_t$ | $\sum_{i=1}^{N_t} p_{it}^2$；取值$[1/N_t, 1]$，越大表示注意力越集中 | 微博热搜榜 | H1b |
| **H2：内容质量** |
| 因变量 | 官方媒体占比 | $\text{Official}_t^c$ | 类别$c$在第$t$天上榜话题中官媒主持的比例；取值[0,1] | 微博热搜榜 + 人工标注 | H2a |
| 因变量(DID) | 官媒话题占比 | $Y_{it}^c$ | 类别$c$中官媒($i=1$)或非官媒($i=0$)话题的上榜频次占比或热度占比 | 微博热搜榜 + 人工标注 | H2稳健性 |
| **H3：注意力再分配** |
| 因变量 | 类别注意力份额 | $\text{Share}_{ct}$ | 类别$c$在第$t$天的总热度占当日全平台热度的比例；$\sum_{i \in c} V_{it} / \sum_{j=1}^{N_t} V_{jt}$ | 微博热搜榜 | H3a, H3b |
| 辅助变量 | 类别上榜频次 | $\text{Count}_{ct}$ | 类别$c$在第$t$天的上榜话题数量 | 微博热搜榜 | H3补充 |
| **H4：注意力密度** |
| 因变量 | 平均在榜时长 | $\text{Duration}_{ct}$ | 类别$c$在第$t$天上榜话题的平均持续时间(小时)；$\frac{1}{N_{ct}} \sum_{i \in c} d_{it}$ | 微博热搜榜 | H4a, H4b |
| 因变量 | 注意力密度 | $\text{Density}_{ct}$ | 类别$c$的单位话题平均热度；$\sum_{i \in c} V_{it} / N_{ct}$ | 微博热搜榜 | H4a, H4b |
| **核心自变量** |
| 政策变量 | 政策虚拟变量 | $\text{Post}_t$ | 若$t \geq$ 2024年10月12日取1，否则为0 | 政策文件 | 全部 |
| 类别变量 | 社会类虚拟变量 | $\text{Social}_c$ | 若类别为"社会"取1，否则为0 | 微博平台分类 | H2-H4 |
| 类别变量 | 娱乐类虚拟变量 | $\text{Entertainment}_c$ | 若类别为"明星"或"明星-内地"取1，否则为0 | 微博平台分类 | H2-H4 |
| 信源变量 | 官媒虚拟变量 | $\text{Official}_i$ | 若话题由官方媒体主持取1，否则为0；官媒包括党媒、政务账号、传统主流媒体 | 人工标注 | H2 DID |
| **控制变量** |
| 时间控制 | 时间趋势 | $\text{Trend}_t$ | 取值1, 2, ..., 608，对应研究期第1天至第608天 | 计算得出 | 全部 |
| 时间控制 | 周内固定效应 | $\text{DOW}_t$ | 周一至周日的虚拟变量组 | 计算得出 | 全部 |
| 时间控制 | 月度固定效应 | $\text{Month}_t$ | 1-12月的虚拟变量组 | 计算得出 | 全部 |
| 时间控制 | 节假日虚拟变量 | $\text{Holiday}_t$ | 若为法定节假日或其前后一天取1，否则为0 | 国务院公告 | 全部 |
| 平台控制 | 平台总热度 | $\text{TotalHeat}_t$ | 第$t$天所有上榜话题的热度值总和；$\sum_{j=1}^{N_t} V_{jt}$ | 微博热搜榜 | H2-H4 |
| 平台控制 | 上榜话题总数 | $\text{TotalCount}_t$ | 第$t$天上榜的独立话题数量$N_t$ | 微博热搜榜 | H1 |
| 类别控制 | 类别总上榜数 | $\text{TotalCount}_{ct}$ | 类别$c$在第$t$天的上榜话题总数 | 微博热搜榜 | H2 DID |

**注释**：
1. 热度值$V_{it}$为微博平台综合阅读量、讨论量、搜索量等多维度数据计算的标准化指标
2. 官方媒体分类由两名研究助理独立标注，Cohen's Kappa = 0.91
3. 所有比例型变量取值范围为[0,1]
4. 时间单位：日度数据，样本期2024年2月1日至2025年10月1日（共608天）


